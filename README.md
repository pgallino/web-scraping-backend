# ğŸ§© backend-base â€” Plantilla profesional para APIs con FastAPI y SQLAlchemy

> **Arquitectura hexagonal (Ports & Adapters) Â· Base de datos integrada Â· Migraciones Alembic Â· Tests BDD y CI/CD listos**

<p align="center">
  <img src="https://img.shields.io/badge/python-3.11%2B-blue" alt="Python version" />
  <img src="https://img.shields.io/badge/FastAPI-0.115%2B-009688?logo=fastapi" alt="FastAPI" />
  <img src="https://img.shields.io/badge/SQLAlchemy-async-orange?logo=python" alt="SQLAlchemy async" />
  <img src="https://img.shields.io/badge/Alembic-migrations-yellow" alt="Alembic" />
  <img src="https://img.shields.io/badge/tests-pytest%20%2B%20BDD-green?logo=pytest" alt="Testing" />
  <img src="https://img.shields.io/badge/docker-ready-2496ED?logo=docker" alt="Docker" />
<img src="https://github.com/pgallino/backend-base/actions/workflows/main.yml/badge.svg?branch=main" alt="GitHub Actions CI" />
  <img src="https://img.shields.io/badge/license-MIT-lightgrey" alt="License MIT" />
</p>

---

## ğŸ“š Ãndice

1. [Resumen](#-resumen)
2. [Arquitectura](#-arquitectura)
3. [Estructura del proyecto](#-estructura-del-proyecto)
4. [Requisitos y stack](#-requisitos-y-stack)
5. [ConfiguraciÃ³n y entorno](#-configuraciÃ³n-y-entorno)
6. [Base de datos y migraciones](#-base-de-datos-y-migraciones)
7. [EjecuciÃ³n en desarrollo](#-ejecuciÃ³n-en-desarrollo)
8. [Pruebas (TDD y BDD)](#-pruebas-tdd-y-bdd)
9. [Makefile y comandos Ãºtiles](#-makefile-y-comandos-Ãºtiles)
10. [CI/CD y despliegue](#-cicd-y-despliegue)
11. [ReutilizaciÃ³n y buenas prÃ¡cticas](#-reutilizaciÃ³n-y-buenas-prÃ¡cticas)

---

## ğŸš€ Resumen

`backend-base` es una plantilla profesional para construir **backends escalables en Python**, con **FastAPI**, **SQLAlchemy asÃ­ncrono** y **Alembic** para la gestiÃ³n de base de datos.

Sigue los principios de **Arquitectura Hexagonal (Ports & Adapters)**, garantizando una separaciÃ³n clara entre dominio, infraestructura y orquestaciÃ³n.

Incluye configuraciÃ³n lista para **tests unitarios y de aceptaciÃ³n (BDD)**, y ejemplos de **despliegue con Docker, Render y AWS**.

### ğŸ¯ Objetivo
Proporcionar una base sÃ³lida, extensible y educativa para proyectos reales, enfocada en:

- DiseÃ±o limpio y mantenible (DDD + Hexagonal)
- Tests integrados desde el inicio (unit + BDD)
- ConfiguraciÃ³n y despliegue reproducibles con Docker
- SeparaciÃ³n clara entre dominio, adaptadores y orquestaciÃ³n

---

## ğŸ§± Arquitectura

El proyecto implementa una **Arquitectura Hexagonal (Ports & Adapters)**, donde cada capa tiene una responsabilidad bien definida.

```text
Adaptador de Entrada (HTTP/CLI)
        â†“
[Fachada de AplicaciÃ³n (Orquestador)]
        â†“ (Usa uno o varios)
[Servicios de AplicaciÃ³n/Dominio]
        â†“ (InteractÃºan con)
[Adaptadores de Salida: Repositorios]
        â†“
Base de Datos (PostgreSQL / SQLite)
```

### Capas principales

### ğŸ—‚ï¸ Capas y Componentes Clave

| Capa/Componente | Rol Principal | Interacciones Clave |
| :--- | :--- | :--- |
| **Adaptadores de Entrada** | Reciben peticiones (HTTP, CLI), validan los datos y delegan en la Fachada. | Solo interactÃºan con la **Fachada de AplicaciÃ³n**. |
| **Fachada de AplicaciÃ³n** | ActÃºa como **orquestador principal** de un caso de uso. | Invoca a uno o mÃ¡s **Servicios de AplicaciÃ³n/Dominio** para ejecutar la lÃ³gica. |
| **Servicios de AplicaciÃ³n/Dominio** | Contienen la lÃ³gica de negocio especÃ­fica y utilizan los Repositorios para datos. | Utilizan los **Repositorios** (Adaptadores de Salida) para obtener o guardar datos. |
| **Dominio** | Contiene **Entidades** y **Reglas de Negocio Puras**. | Son utilizados e implementados por los **Servicios** (las Entidades viajan entre capas). |
| **Adaptadores de Salida: Repositorios** | Implementan la interfaz de persistencia (el Puerto) utilizando tecnologÃ­a especÃ­fica (**SQLAlchemy async**). | InteractÃºan con la **Base de Datos**. |
| **Infraestructura** | Servicios transversales: configuraciÃ³n, *logging*, *fixtures*, etc. | Provee herramientas de soporte al resto de las capas. |

Esta separaciÃ³n facilita el testing, la evoluciÃ³n del cÃ³digo y la independencia del framework o base de datos.

---

## ğŸ—‚ï¸ Estructura del proyecto (resumen)

Una vista compacta de los elementos principales del repositorio, con comentarios sobre su rol:

```text
## ğŸ—‚ï¸ Estructura del proyecto

Una vista en forma de Ã¡rbol (resumen), para localizar rÃ¡pidamente carpetas y archivos clave:

```text
alembic.ini
docker-compose.dev.yml
Dockerfile
Dockerfile.dev
Makefile
pyproject.toml
README.md
scripts/                 # scripts de utilidad (start/cleanup)
alembic/
â”œâ”€ env.py
â””â”€ versions/
   â””â”€ 0001_create_tool_table.py
src/
â”œâ”€ config.py
â”œâ”€ log.py
â”œâ”€ adapters/
â”‚  â”œâ”€ api/
â”‚  â”‚  â”œâ”€ middleware.py
â”‚  â”‚  â””â”€ routes/
â”‚  â”‚     â”œâ”€ health.py
â”‚  â”‚     â””â”€ tools.py
â”‚  â”œâ”€ cli/
â”‚  â”‚  â””â”€ cli.py
â”‚  â””â”€ db/
â”‚     â”œâ”€ session.py
â”‚     â””â”€ repositories/
â”‚        â””â”€ tool_repository.py
â”œâ”€ application/
â”‚  â”œâ”€ api_app.py
â”‚  â”œâ”€ cli_app.py
â”‚  â””â”€ facade.py
â””â”€ domain/
   â”œâ”€ tool.py
   â””â”€ tool_service.py
tests/
â”œâ”€ acceptance/         # BDD scenarios (pytest-bdd + Gherkin)
â”œâ”€ integration/        # tests que usan DB real / Async fixtures
â””â”€ unit/               # tests de lÃ³gica pura y adapters mockeados
```

---

## ğŸ’» Requisitos y stack

- Python **3.11+** (preparado para 3.12)
- **FastAPI** â€” framework principal
- **SQLAlchemy async** â€” ORM asÃ­ncrono
- **Alembic** â€” migraciones de base de datos
- **pytest + pytest-bdd** â€” testing unitario y de aceptaciÃ³n
- **Docker Compose** â€” entorno reproducible
- **GitHub Actions** â€” CI/CD de ejemplo

---

## âš™ï¸ ConfiguraciÃ³n y entorno

El proyecto usa un archivo `.env` para variables de entorno. Ejemplo (`.env.example`):

```bash
ENVIRONMENT=dev
PORT=8000
DB_URL_SYNC=sqlite:///dev.db
DB_URL_ASYNC=sqlite+aiosqlite:///dev.db
ALLOWED_ORIGINS=http://localhost:3000
SECRET_KEY=super-secret-key
API_KEY=dev_api_key
```

> âš ï¸ **No subas secretos reales al repositorio.** Usa secrets en CI/CD o servicios como Render o AWS.

### ConfiguraciÃ³n en desarrollo (recomendado)

Para facilitar el desarrollo local, incluimos un archivo de ejemplo `.env.example` en la raÃ­z del proyecto.

Flujo recomendado para nuevos desarrolladores:

1. Copia el ejemplo a `.env` (archivo local, nunca comiteado):

```bash
cp .env.example .env
```

---

## ğŸ—„ï¸ Base de datos y migraciones

Alembic se utiliza para versionar el esquema de la base de datos.

### Alembic

Alembic es la herramienta de migrations para SQLAlchemy: permite crear "revisiones" que describen cambios en el esquema (crear tablas, columnas, Ã­ndices) y aplicarlas de forma ordenada en cualquier entorno. En este proyecto usamos Alembic para mantener el historial del esquema y aplicarlo en CI / despliegues.

Hemos aÃ±adido objetivos en el `Makefile` para envolver Alembic y simplificar el flujo. Usa los objetivos `make` desde tu mÃ¡quina o dentro del contenedor:

```bash
# Aplicar migraciones (upgrade hasta head):
make alembic-upgrade

# Ejecutar migraciones dentro del contenedor de desarrollo:
make migrate
```

Usar `make` garantiza que `PYTHONPATH` y el contexto de ejecuciÃ³n estÃ©n correctamente definidos para que Alembic encuentre el mÃ³dulo `src`.

### Variables relevantes

- `DB_URL_SYNC` â€” URL sincrÃ³nica (usada por Alembic)
- `DB_URL_ASYNC` â€” URL asÃ­ncrona (usada por la app)

Nota: Alembic requiere un driver sincrÃ³nico; la app usa un driver asÃ­ncrono (ej: `postgresql+asyncpg://`). En CI y despliegue define ambas variables de entorno segÃºn corresponda.

---

## ğŸ§‘â€ğŸ’» EjecuciÃ³n en desarrollo

Con **Docker Compose** (recomendado):

```bash

# Levantar los servicios de desarrollo (api + cli)
docker compose -f docker-compose.dev.yml up -d

# Entrar al contenedor CLI (para ejecutar comandos Typer / make)
docker compose -f docker-compose.dev.yml exec cli sh

# Entrar al contenedor API (uvicorn corre en segundo plano)
docker compose -f docker-compose.dev.yml exec api sh
```

### Desarrollo â€” hay dos aplicaciones (API y CLI)

En este repositorio conviven dos "apps" distintas que comparten la misma base de cÃ³digo y la misma fachada de aplicaciÃ³n:

- API (FastAPI): el servidor HTTP que expone los endpoints REST/OpenAPI. El entrypoint de la API estÃ¡ en `src.application.api_app` y en desarrollo se ejecuta con `uvicorn`.
- CLI (Typer): una interfaz de lÃ­nea de comandos que reutiliza la lÃ³gica de la aplicaciÃ³n (fachada). El entrypoint del CLI estÃ¡ en `src.application.cli_app`.

Por quÃ© dos aplicaciones?
- Muestra que, reutilizando la misma fachada de aplicaciÃ³n y sin modificar el cÃ³digo interno del dominio, se pueden exponer mÃºltiples interfaces (por ejemplo HTTP y CLI) que comparten exactamente la misma lÃ³gica. ![CLI & API architecture](doc/img/cli_api.png)

Arquitectura de Docker / dependencias

- Archivos de requirements:
        - `requirements-dev.txt` â€” dependencias para desarrollo (typer, pytest, herramientas de formateo). Se usa en la imagen `Dockerfile.dev`.
        - `requirements-prod.txt` â€” dependencias mÃ­nimas para producciÃ³n. Se usa en `Dockerfile`.

- Dockerfiles:
        - `Dockerfile.dev` â€” imagen pensada para desarrollo: incluye herramientas de testing/format y utilidades para iterar rÃ¡pido.
        - `Dockerfile` â€” imagen optimizada para producciÃ³n: minimal, no incluye herramientas de desarrollo y usa `requirements-prod.txt`.

- Compose para desarrollo:
        - `docker-compose.dev.yml` â€” orquesta los servicios locales para desarrollo (normalmente `api` y `cli`).

CÃ³mo usar la API y la CLI (paso a paso)

1) Construir la imagen de desarrollo y levantar los servicios

```bash
docker compose -f docker-compose.dev.yml up -d --build
```

2) Entrar a la shell del CLI (Ãºtil para ejecutar comandos Typer):

```bash
docker compose -f docker-compose.dev.yml exec cli sh
# dentro del contenedor:
python -m src.application.cli_app list-tools
python -m src.application.cli_app create "AWS" --description "Despliegue en la nube" --link "https://aws.com"
```

3) Usar la API desde el host (documentaciÃ³n interactiva en /docs):

```bash
curl http://localhost:8000/  # o la ruta health/ segÃºn la app
# Abrir la UI de OpenAPI en el navegador:
http://localhost:8000/docs
```

4) Ejecutar migraciones (Alembic) usando el contenedor CLI (usa `.env` para DB_URL_SYNC):

```bash
docker compose -f docker-compose.dev.yml exec cli alembic upgrade head
```

Consejos rÃ¡pidos
- Si quieres menos ruido en logs, define en tu `.env`:

```
LOG_LEVEL=INFO
```

---

## ğŸ§ª Pruebas (TDD y BDD)

El proyecto incluye **tests unitarios y de aceptaciÃ³n**.

### Estructura

```
tests/
â”œâ”€â”€ domain/           # Tests unitarios (lÃ³gica pura)
â””â”€â”€ acceptance/       # Tests BDD (pytest-bdd + Gherkin)
```

### Comandos

```bash
# Ejecuta todos los tests (unitarios + acceptance)
make test

# Ejecuta tests unitarios y genera reporte de cobertura enfocado en
# los paquetes de dominio y adaptadores. Por defecto medimos cobertura
# sobre `src/domain` y `src/adapters`. Ajusta `.coveragerc` para omitir
# mÃ³dulos concretos (por ejemplo `src/adapters/api` o
# `src/domain/exceptions`) si querÃ©s excluirlos del informe.
make test-unit

# Ejecuta solo los tests de aceptaciÃ³n (BDD)
make test-acceptance
```

### Pruebas de integraciÃ³n

Las pruebas de integraciÃ³n en este proyecto verifican la interacciÃ³n real entre los adaptadores (por ejemplo `adapters/db`) y la base de datos o servicios externos en un entorno controlado. Son mÃ¡s completas que los tests unitarios, pero mÃ¡s ligeras y orientadas a integraciÃ³n que los tests de aceptaciÃ³n BDD.

- UbicaciÃ³n: `tests/integration/`.
- QuÃ© cubren: comportamiento de los repositorios, migraciones mÃ­nimas, y flujos que requieren interacciÃ³n con la base de datos real (no mocks). No ejecutan la app HTTP completa con BDD (eso queda para `tests/acceptance`).
- Fixtures relevantes: las fixtures asÃ­ncronas que crean una `AsyncEngine` y `AsyncSession` de prueba se encuentran en `tests/integration/conftest.py` y preparan un esquema limpio para cada grupo de tests.

```bash
make test-integration
```

> Las pruebas BDD usan `TestClient` de FastAPI y se ejecutan sin servidor externo.

Detalles prÃ¡cticos sobre `TestClient` y los acceptance tests

- QuÃ© hace `TestClient`: monta la aplicaciÃ³n ASGI (FastAPI) en memoria y permite hacer peticiones HTTP a la app desde pytest sin necesidad de arrancar un proceso externo. Esto habilita pruebas rÃ¡pidas e independientes del entorno.

- Inicio y eventos de aplicaciÃ³n: `TestClient` dispara los eventos de `startup` y `shutdown` de FastAPI, por lo que cualquier inicializaciÃ³n (conexiÃ³n a DB en tests, carga de fixtures) definida en el `lifespan` o `startup` se ejecuta automÃ¡ticamente.

- Fixtures y preparaciÃ³n de la DB: en `tests/acceptance/conftest.py` hay fixtures que crean/aseguran las tablas, limpian filas entre escenarios y reinician secuencias (SQLite). AsegÃºrate de que las fixtures hagan _arranque limpio_ (crear tablas si hace falta y truncar) para que cada escenario sea determinista.

- CÃ³mo ejecutar los acceptance tests:

```bash
# desde el host (usa las variables de entorno del entorno de desarrollo):
make test-acceptance

# ejecutar un escenario o un conjunto especifico (mÃ¡s verboso):
pytest tests/acceptance -k "herramientas" -s -vv
```

Con esto las pruebas BDD permanecen rÃ¡pidas, deterministas y fÃ¡ciles de ejecutar tanto en tu mÃ¡quina como en CI.

---

## ğŸ§° Makefile y comandos Ãºtiles

| Comando | DescripciÃ³n |
|---:|:---|
| `make help` (por defecto) | Muestra la ayuda con los comandos principales del proyecto.
| `make format` | Formatea el cÃ³digo con `black` e `isort`.
| `make format-check` | Verifica el formato sin modificar archivos (comprobar antes de commitear).
| `make lint` | Ejecuta chequeos estÃ¡ticos (mypy) para tipos.
| `make check` | Ejecuta `format-check` y `lint` (Ãºtil en CI pre-merge).
| `make test` | Ejecuta todos los tests (unit + acceptance). |
| `make test-unit` | Ejecuta tests unitarios y genera cobertura sobre `src/domain` y `src/adapters` (usa `.coveragerc` para omitir mÃ³dulos del informe). |
| `make test-acceptance` | Ejecuta solo los tests de aceptaciÃ³n (BDD). |
| `make test-integration` | Ejecuta tests de integraciÃ³n (repositorios y DB) en `tests/integration/`. |
| `make alembic-upgrade` | Aplica las migraciones hasta `head` usando Alembic.
| `make migrate` | Ejecuta las migraciones dentro del contenedor de desarrollo (con `PYTHONPATH` adecuado).
| `make ci` | Atajo para `format-check`, `lint` y `test` â€” pensado para CI.

---

## â˜ï¸ CI/CD y despliegue

Esta plantilla incluye workflows de ejemplo en `.github/workflows/` y patrones recomendados para desplegar en Render, AWS (App Runner/ECS) o usando Neon como base de datos.

### Neon (Postgres serverless)

- Define en GitHub Secrets la URL de Neon. En este proyecto conviene publicar ambas variantes segÃºn uso:
   - `DB_URL_ASYNC` â€” p. ej. `postgresql+asyncpg://user:pass@host/db` (usada por la app FastAPI)
   - `DB_URL_SYNC` â€” p. ej. `postgresql+psycopg2://user:pass@host/db` (Ãºtil para ejecutar Alembic desde un job/contenedor sync)

### AWS (ECR + App Runner)

Los workflows de despliegue en este repositorio ya se encargan de ejecutar las migraciones en Neon antes de promover la nueva versiÃ³n, por lo que no es necesario ejecutar migraciones manualmente durante el despliegue. Para desplegar en AWS normalmente sÃ³lo necesitas construir y subir la imagen a ECR, configurar el servicio App Runner y asegurarte de que los secrets/variables estÃ©n presentes en GitHub Actions o en el entorno de ejecuciÃ³n.

Variables/Secrets clave en AWS:

- `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION`, `ECR_REPOSITORY`
- `DB_URL_ASYNC`, `SECRET_KEY`, `ALLOWED_ORIGINS`
- `DB_URL_ASYNC`, `SECRET_KEY`, `ALLOWED_ORIGINS`, `API_KEY`


### Render

El pipeline de despliegue de este repositorio invoca el workflow de migraciones en Neon, de modo que no es necesario ejecutar comandos de migraciÃ³n manualmente en Render. Configura el servicio en Render para que use la imagen que publica el workflow y aÃ±ade los secrets/variables necesarios.

Variables/Secrets a configurar en Render:

- `RENDER_API_KEY`, `RENDER_SERVICE_ID`, `DB_URL_ASYNC`, `ALLOWED_ORIGINS`
- `RENDER_API_KEY`, `RENDER_SERVICE_ID`, `DB_URL_ASYNC`, `ALLOWED_ORIGINS`, `API_KEY`

### GitHub Actions

Workflows incluidos (ejemplos):

- `main.yml` â€” checks y tests (`make check`, `make test`).
- `deploy-render.yml` â€” ejemplo para disparar un deploy en Render.
- `deploy-aws.yml` â€” ejemplo para build/push a ECR y despliegue;

Nota importante: los workflows estÃ¡n listos como ejemplos; para que funcionen define los secrets mencionados en Settings â†’ Secrets. En este repositorio los pipelines de despliegue ya invocan el workflow de migraciones (`deploy-neon.yml`) y por tanto las migraciones se ejecutan automÃ¡ticamente contra Neon durante el proceso de despliegue â€” no hace falta ejecutarlas manualmente. AsegÃºrate de que `DB_URL_SYNC`/`DB_URL_ASYNC` y demÃ¡s secrets estÃ©n definidos en GitHub Actions para que el job de migraciones pueda conectarse a Neon.

### Secrets a crear (copia/pega)

A continuaciÃ³n tienes una tabla con los secrets y variables que aparecen en los workflows; crea estos secrets en GitHub (Settings â†’ Secrets and variables â†’ Actions) y configura las variables de entorno equivalentes en tu proveedor (Render, ECS, App Runner) para runtime:

| Secret / Variable | Usado por | DescripciÃ³n |
|---|---|---|
| NEON_DB_SYNC | `deploy-neon.yml` (job `migrate`) | URL sÃ­ncrona de Neon (ej. `postgresql+psycopg2://user:pass@host:port/db`) â€” usada por Alembic en el job de migraciones |
| DB_URL_ASYNC | runtime (Render / ECS / App Runner) | URL asÃ­ncrona para la app FastAPI (ej. `postgresql+asyncpg://user:pass@host/db`) |
| DB_URL_SYNC | (opcional) runtime / CI | Variante sÃ­ncrona si alguna tarea la necesita en runtime; `NEON_DB_SYNC` se pasa a los workflows para migraciones |
| AWS_ACCESS_KEY_ID | `deploy-aws.yml` | Credencial AWS (user con permisos ECR/Push) |
| AWS_SECRET_ACCESS_KEY | `deploy-aws.yml` | Credencial AWS |
| AWS_ACCOUNT_ID | `deploy-aws.yml` | ID de la cuenta AWS (usado para tag de la imagen) |
| ECR_REPOSITORY | `deploy-aws.yml` | Nombre del repositorio en ECR (se puede dejar en env del workflow) |
| RENDER_API_KEY | `deploy-render.yml` | API key para la cuenta Render (usar secret) |
| RENDER_SERVICE_ID | `deploy-render.yml` | ID del servicio en Render que se va a desplegar |
| RENDER_URL | `deploy-render.yml` | URL pÃºblica para health-check (opcional; usada por el workflow) |
| SECRET_KEY | runtime | Clave secreta de la aplicaciÃ³n (runtime) |
| ALLOWED_ORIGINS | runtime | OrÃ­genes permitidos para CORS (runtime) |
| API_KEY | runtime (API) | API key para proteger endpoints HTTP; si se establece, el servidor requerirÃ¡ el header `X-API-Key` en peticiones protegidas. |

> Nota: `NEON_DB_SYNC` es el secret requerido por `deploy-neon.yml` y el workflow lo exporta como `DB_URL_SYNC` para ejecutar `make alembic-upgrade`. `DB_URL_ASYNC` debe establecerse en el entorno del servicio para que la app use el driver asÃ­ncrono en producciÃ³n.

---

## â™»ï¸ ReutilizaciÃ³n y buenas prÃ¡cticas

La arquitectura estÃ¡ pensada para ser **reutilizable y desacoplada**:

- El **dominio** y la **fachada** no dependen de frameworks.
- Se puede cambiar la base de datos sin modificar la lÃ³gica de negocio.
- Permite testear el dominio de forma aislada.
- Facilita extender a otros tipos de adaptadores (gRPC, CLI, eventos, etc.).

> MantÃ©n las entidades puras, define interfaces en el dominio y deja las implementaciones en `adapters/`.

---

ğŸ“˜ **Con esta plantilla tendrÃ¡s un backend modular, testeable y preparado para producciÃ³n, sin sacrificar claridad ni mantenibilidad.**
